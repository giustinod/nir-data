{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHwejB3R/TqWcRv5ubLiWA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giustinod/nir-data/blob/main/Preparazione_dataset_dvoptic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importazioni librerie e definizione funzioni di utilitÃ **"
      ],
      "metadata": {
        "id": "99nUHmVgLSh0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwZpkhQ3sgY4",
        "outputId": "5ae632d8-f36e-4258-daee-aed3ba07cc66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spectral in /usr/local/lib/python3.7/dist-packages (0.23)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spectral) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.7/dist-packages (from pyod) (0.56.2)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.7.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod) (0.12.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pyod) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyod) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyod) (1.1.0)\n",
            "Requirement already satisfied: setuptools<60 in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->pyod) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->pyod) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->pyod) (4.12.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->pyod) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.51->pyod) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.51->pyod) (4.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (3.0.9)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (0.5.2)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels->pyod) (2022.2.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cleanlab in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.0.2)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->cleanlab) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->cleanlab) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.0->cleanlab) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->cleanlab) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->cleanlab) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->cleanlab) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikeras[tensorflow] in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikeras[tensorflow]) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=3 in /usr/local/lib/python3.7/dist-packages (from scikeras[tensorflow]) (4.12.0)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikeras[tensorflow]) (21.3)\n",
            "Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from scikeras[tensorflow]) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras[tensorflow]) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras[tensorflow]) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=0.21->scikeras[tensorflow]) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.0.7)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.5.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (57.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (14.0.6)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.26.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.48.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.7.0->scikeras[tensorflow]) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->scikeras[tensorflow]) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.25.11)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.2.0)\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install sklearn\n",
        "!pip3 install spectral\n",
        "!pip3 install pyod\n",
        "!pip3 install cleanlab\n",
        "!pip3 install scikeras[tensorflow]\n",
        "\n",
        "## Import external libraries\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import scipy\n",
        "from scipy import newaxis as nA\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "from spectral import *\n",
        "import spectral.io.envi as envi\n",
        "\n",
        "from pyod.models.copod import COPOD\n",
        "\n",
        "import multiprocessing\n",
        "import time\n",
        "from datetime import datetime\n",
        "import concurrent.futures\n",
        "from multiprocessing import Process\n",
        "\n",
        "def snv(input_data):\n",
        "    # Define a new array and populate it with the corrected data  \n",
        "    # return (input_data - np.mean(input_data, axis=0)) / np.std(input_data, axis=0)\n",
        "    output_data = np.zeros_like(input_data)\n",
        "    for i in range(input_data.shape[0]):\n",
        "      # if np.all(np.std(input_data[i,:]) != 0):\n",
        "      # Apply correction\n",
        "      output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / (np.std(input_data[i,:]))\n",
        "      # else:\n",
        "      # output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:]))\n",
        "    return output_data\n",
        "\n",
        "def plot_matrix(matrixToPlot, title='', classList=[]):\n",
        "    # colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)]\n",
        "    colors = ['b','c','r','g','w','k']\n",
        "    cm = LinearSegmentedColormap.from_list('custom_RGB_cmap', colors, N=len(classList))\n",
        "    norm = plt.Normalize(vmin=0, vmax=len(classList) - 1)\n",
        "    handles = [plt.Rectangle((0, 0), 0, 0, color=cm(norm(i)), label=str(classList[i])) for i in range(len(classList))]\n",
        "    plt.imshow(matrixToPlot, norm=norm, cmap=cm)\n",
        "    plt.legend(handles=handles, title='Class', bbox_to_anchor=(1, 0), loc='lower right', bbox_transform=plt.gcf().transFigure)\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(title + '.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "def mlr(x, y, order):\n",
        "    \"\"\"Multiple linear regression fit of the columns of matrix x \n",
        "    (dependent variables) to constituent vector y (independent variables)\n",
        "    \n",
        "    order -     order of a smoothing polynomial, which can be included \n",
        "                in the set of independent variables. If order is\n",
        "                not specified, no background will be included.\n",
        "    b -         fit coeffs\n",
        "    f -         fit result (m x 1 column vector)\n",
        "    r -         residual   (m x 1 column vector)\n",
        "    \"\"\"\n",
        "    if order > 0:\n",
        "        s = scipy.ones((len(y),1))\n",
        "        for j in range(order):\n",
        "            s = scipy.concatenate((s,(scipy.arange(0,1+(1.0/(len(y)-1)),1.0/(len(y)-1))**j)[:x.shape[0],nA]), 1)\n",
        "        X = scipy.concatenate((x, s), 1)\n",
        "    else:\n",
        "        X = x\n",
        "    \n",
        "    #calc fit b=fit coefficients\n",
        "    b = scipy.dot(scipy.dot(scipy.linalg.pinv(scipy.dot(scipy.transpose(X),X)),scipy.transpose(X)),y)\n",
        "    f = scipy.dot(X,b)\n",
        "    r = y - f\n",
        "\n",
        "    return b,f,r\n",
        "\n",
        "def emsc(myarray, order = 1, fit = None):\n",
        "    \"\"\"Extended multiplicative scatter correction (Ref H. Martens)\n",
        "    myarray -   spectral data for background correction\n",
        "    order -     order of polynomial\n",
        "    fit -       if None then use average spectrum, otherwise provide a spectrum\n",
        "                as a column vector to which all others fitted\n",
        "    corr -      EMSC corrected data\n",
        "    mx -        fitting spectrum\n",
        "    \"\"\"\n",
        "    \n",
        "    #choose fitting vector\n",
        "    if fit:\n",
        "        mx = fit\n",
        "    else:\n",
        "        mx = scipy.mean(myarray, axis=0)[:,nA]\n",
        "\n",
        "    #do fitting\n",
        "    corr = scipy.zeros(myarray.shape)\n",
        "    for i in range(len(myarray)):\n",
        "        if np.count_nonzero(myarray[i,:]) > 0:\n",
        "            b,f,r = mlr(mx, myarray[i,:][:,nA], order)\n",
        "            corr[i,:] = scipy.reshape((r/b[0,0]) + mx, (corr.shape[1],))\n",
        "\n",
        "    assert not np.any(np.isnan(corr))\n",
        "    return corr\n",
        "\n",
        "def data_augmentation(scan):\n",
        "  ## Standardize on columns\n",
        "  if np.count_nonzero(scan) > 0:\n",
        "      svn_scan = snv(scan)\n",
        "      msc_scan = emsc(scan)\n",
        "      scan1 = np.concatenate((scan, svn_scan, msc_scan,\\\n",
        "                  savgol_filter(scan, w, polyorder = p, deriv=1),\\\n",
        "                  savgol_filter(svn_scan, w, polyorder = p, deriv=1),\\\n",
        "                  savgol_filter(msc_scan, w, polyorder = p, deriv=1)), axis = 1)\n",
        "  else:\n",
        "      scan1 = np.zeros((scan.shape[0], scan.shape[1] * 6), dtype=np.float32)\n",
        "\n",
        "  print('{} - Data augmentation chunk: {} -> {}'.format(datetime.now(), scan.shape, scan1.shape))\n",
        "  return scan1\n",
        "\n",
        "# Check speculari\n",
        "def outliers_speculari(input_data):\n",
        "\n",
        "  ''' Restituisce gli indici degli spettri che hanno caratteristiche di speculari'''\n",
        "  # per lo spettro IR [1050,1650]nm assumiamo:\n",
        "  IR_delta_max = 0.5\n",
        "  IR_lambda_max = 1.2\n",
        "  # per lo spettro VNIR [[400, 600], [800, 900]]nm assumiamo:\n",
        "  VNIR_lambda_max = 1.2\n",
        "\n",
        "  offset = int((1010 - 400) / 10)\n",
        "  offset2 = int((600 - 400) / 10)\n",
        "  offset3 = int((800 - 400) / 10)\n",
        "  offset4 = int((900 - 400) / 10)\n",
        "  speculari_VNIR = np.where((np.max(input_data[:, :offset2], axis = 1) > VNIR_lambda_max) | (np.max(input_data[:, offset3:offset4], axis = 1) > VNIR_lambda_max)) \n",
        "  speculari_IR = np.where((np.max(input_data[:, offset + 1:], axis = 1) > IR_lambda_max) | ((np.max(input_data[:, offset + 1:], axis = 1) - np.min(input_data[:, offset + 1:], axis = 1)) > IR_delta_max))\n",
        "\n",
        "  # print('Speculari IR: ', speculari_IR)\n",
        "  # print('Speculari VNIR: ', speculari_VNIR)\n",
        "  speculari = np.unique(np.concatenate((speculari_IR[0], speculari_VNIR[0]), axis=0))\n",
        "  # print('Speculari: ', speculari)\n",
        "  return speculari\n",
        "\n",
        "def conv(cl):\n",
        "    if cl == 'Carta':\n",
        "        return 0\n",
        "    if cl == 'VetroCarta':\n",
        "        return 1\n",
        "    if cl == 'Ceramica':\n",
        "        return 2\n",
        "    if cl == 'Opalino':\n",
        "        return 3\n",
        "    if cl == 'Plastica':\n",
        "        return 4\n",
        "    if cl == 'Vetro':\n",
        "        return 5\n",
        "    if cl == 'VetroCeramica':\n",
        "        return 6\n",
        "    if cl == 'BackGround':\n",
        "        return 7\n",
        "    return 9   # default case if x is not found\n",
        "\n",
        "selected_classes = (0, 1, 2, 3, 4, 5, 6, 7)\n",
        "n_classes = len(selected_classes)\n",
        "\n",
        "## Settings for the smooth derivatives using a Savitsky-Golay filter\n",
        "w = 7 ## Sav.Gol window size\n",
        "p = 2 ## Sav.Gol polynomial degree\n",
        "\n",
        "n_features = 182\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dalle immagini HDR estraggo i CSV eliminando i pixel a zero e gli intorni (+ o - 3 wl)**"
      ],
      "metadata": {
        "id": "vNe5AWaILA8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Authenticate to google drive and mount drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "root = '/content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/'\n",
        "\n",
        "# mpy = COPOD()\n",
        "\n",
        "# cfr. https://stackoverflow.com/questions/9132114/indexing-numpy-array-neighbours-efficiently\n",
        "def neighbors(x):\n",
        "    return np.array([x-3, x-2, x-1, x, x+1, x+2, x+3])\n",
        "\n",
        "for path, subdirs, files in os.walk(root):\n",
        "    # print('Path: ', path)\n",
        "    for name in files:\n",
        "        if name.endswith('hdr'):\n",
        "            print('{} - Opening {}'.format(datetime.now(), os.path.join(path, name)))\n",
        "            MyImg = envi.open(os.path.join(path, name))\n",
        "            np_img = np.array(MyImg.load())\n",
        "            # print('{} - Image shape: {}'.format(datetime.now(), np_img.shape))\n",
        "            # print('{} - Image rows*cols: {}*{}'.format(datetime.now(), MyImg.nrows, MyImg.ncols))\n",
        "            X = np.resize(np_img, (np_img.shape[0] * np_img.shape[1], np_img.shape[2]))\n",
        "            # print('{} - Conv. to Numpy array {}'.format(datetime.now(), X.shape))\n",
        "            # spec_outliers = outliers_speculari(X)\n",
        "            # print('{} - Outliers Speculari # {}'.format(datetime.now(), np.unique(spec_outliers).shape))\n",
        "            # fitted = mpy.fit(X)\n",
        "            # c_outliers = mpy.predict(X)\n",
        "            # copod_outliers = np.where(c_outliers >= 1)\n",
        "            # print('{} - Outliers COPOD # {}'.format(datetime.now(), copod_outliers[0].shape))\n",
        "            # mask_outliers = spec_outliers # np.unique(np.concatenate((spec_outliers, copod_outliers[0])))\n",
        "            mask_all_zeroes = np.where(~X.any(axis=1))[0]\n",
        "            nb_all_zeroes = np.unique(np.concatenate([neighbors(i) for i in mask_all_zeroes]))\n",
        "            # print('{} - Rows having all zeroes # {}'.format(datetime.now(), mask_all_zeroes))\n",
        "            # print('{} - Rows having all zeroes in the neighborhood # {} - {}'.format(datetime.now(), nb_all_zeroes, nb_all_zeroes.shape))\n",
        "            nb_all_zeroes = np.delete(nb_all_zeroes, [0, 1, 2, nb_all_zeroes.shape[0]-3, nb_all_zeroes.shape[0]-2, nb_all_zeroes.shape[0]-1], axis = 0)\n",
        "            X = np.delete(X, nb_all_zeroes, axis = 0)\n",
        "            # print('{} - Rows having all zeroes in the neighborhood # {} - {}'.format(datetime.now(), nb_all_zeroes, nb_all_zeroes.shape))\n",
        "            print('{} - Result size # {}'.format(datetime.now(), X.shape))\n",
        "            cols = np.concatenate([np.arange(400, 1010, 10), np.arange(1050, 1655, 5)])\n",
        "            df = pd.DataFrame(X, columns = cols)\n",
        "            date_ = name.split('_')[0]\n",
        "            class_ = name.split('_')[1]\n",
        "            class_col = np.full(X.shape[0], class_)\n",
        "            csv = df.insert(0, \"Class\", class_col)\n",
        "            filename = name.replace('hdr', 'csv')\n",
        "            print('{} - csv # {}'.format(datetime.now(), filename))\n",
        "            df.to_csv('/content/drive/MyDrive/Freelancer/GraiNit/dvoptic/training/' + filename, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdgtY5To-w6h",
        "outputId": "657f78a6-24c2-4ff4-995b-1392a9352c01"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "2022-09-22 09:19:07.995205 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/23062022_Ceramica_2Merge.hdr\n",
            "2022-09-22 09:19:09.773284 - Result size # (46481, 182)\n",
            "2022-09-22 09:19:09.778704 - csv # 23062022_Ceramica_2Merge.csv\n",
            "2022-09-22 09:19:16.666024 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Ceramica_Sassi0Merge.hdr\n",
            "2022-09-22 09:19:18.501656 - Result size # (40295, 182)\n",
            "2022-09-22 09:19:18.506717 - csv # 04072022_Ceramica_Sassi0Merge.csv\n",
            "2022-09-22 09:19:24.495302 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Ceramica_Scure0Merge.hdr\n",
            "2022-09-22 09:19:26.498311 - Result size # (45427, 182)\n",
            "2022-09-22 09:19:26.503398 - csv # 04072022_Ceramica_Scure0Merge.csv\n",
            "2022-09-22 09:19:33.598905 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Ceramica_Latterizio1Merge.hdr\n",
            "2022-09-22 09:19:35.444949 - Result size # (20640, 182)\n",
            "2022-09-22 09:19:35.448651 - csv # 04072022_Ceramica_Latterizio1Merge.csv\n",
            "2022-09-22 09:19:38.438740 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Ceramica_Colore1Merge.hdr\n",
            "2022-09-22 09:19:40.387177 - Result size # (65016, 182)\n",
            "2022-09-22 09:19:40.406376 - csv # 04072022_Ceramica_Colore1Merge.csv\n",
            "2022-09-22 09:19:51.561950 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Ceramica_Bianca2Merge.hdr\n",
            "2022-09-22 09:19:53.503015 - Result size # (62592, 182)\n",
            "2022-09-22 09:19:53.510400 - csv # 04072022_Ceramica_Bianca2Merge.csv\n",
            "2022-09-22 09:20:03.029680 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Vetro_5Merge.hdr\n",
            "2022-09-22 09:20:04.904858 - Result size # (54889, 182)\n",
            "2022-09-22 09:20:04.910440 - csv # 04072022_Vetro_5Merge.csv\n",
            "2022-09-22 09:20:13.427690 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Vetro_1Merge.hdr\n",
            "2022-09-22 09:20:15.249713 - Result size # (61725, 182)\n",
            "2022-09-22 09:20:15.255092 - csv # 04072022_Vetro_1Merge.csv\n",
            "2022-09-22 09:20:24.783660 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Plastica_Buona2Merge.hdr\n",
            "2022-09-22 09:20:26.578305 - Result size # (6022, 182)\n",
            "2022-09-22 09:20:26.581210 - csv # 04072022_Plastica_Buona2Merge.csv\n",
            "2022-09-22 09:20:27.483336 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Plastica_Buona1Merge.hdr\n",
            "2022-09-22 09:20:29.290831 - Result size # (30207, 182)\n",
            "2022-09-22 09:20:29.295089 - csv # 04072022_Plastica_Buona1Merge.csv\n",
            "2022-09-22 09:20:34.075723 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Opalino_1Merge.hdr\n",
            "2022-09-22 09:20:35.849024 - Result size # (10311, 182)\n",
            "2022-09-22 09:20:35.851955 - csv # 04072022_Opalino_1Merge.csv\n",
            "2022-09-22 09:20:37.359061 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Opalino_0Merge.hdr\n",
            "2022-09-22 09:20:39.050583 - Result size # (34499, 182)\n",
            "2022-09-22 09:20:39.054992 - csv # 04072022_Opalino_0Merge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predisposizione dataset per training, validazione e test**"
      ],
      "metadata": {
        "id": "Rhly9jHTK0YC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Import external libraries\n",
        "\n",
        "roots = ['/content/drive/MyDrive/Freelancer/GraiNit/dvoptic/training/',]\n",
        "\n",
        "columns = np.array(['Class'])\n",
        "\n",
        "df_train = pd.DataFrame(data=None, columns=columns)\n",
        "df_test = pd.DataFrame(data=None, columns=columns)\n",
        "df_val = pd.DataFrame(data=None, columns=columns)\n",
        "\n",
        "perc_train = 0.55\n",
        "perc_test = 0.2\n",
        "perc_val = 0.25\n",
        "\n",
        "# dataset ricevuti dal 1 giugno con aggiunta BG 25 maggio\n",
        "perc_class = [0.5, 0.25, 0.25, 1, 1, 0.5, 0.51, 0.13]\n",
        "\n",
        "for r in roots:\n",
        "    for path, subdirs, files in os.walk(r):\n",
        "        for name in files:\n",
        "            if name.endswith('csv'):\n",
        "                df = pd.read_csv(path + '/' + name, header = 0)\n",
        "                m = re.search('04072022_(.+?)_(.+?).csv', name)\n",
        "                class_ = conv(m.group(1))\n",
        "                df.replace(m.group(1), class_, inplace = True)\n",
        "                df.dropna(how='any', inplace = True)\n",
        "                df.rename(columns={'Unnamed: 0':'Class'}, inplace = True)\n",
        "                cols = np.concatenate([['Class'], np.concatenate([np.arange(400, 1010, 10), np.arange(1050, 1655, 5)])])\n",
        "                df.columns = cols\n",
        "                n_rows = df.shape[0]\n",
        "                n_rows_train = round(n_rows * perc_train * perc_class[class_])\n",
        "                n_rows_test = round(n_rows * perc_test * perc_class[class_])\n",
        "                n_rows_val = round(n_rows * perc_val * perc_class[class_])\n",
        "                print('{} ({}): {}, {}'.format(m.group(1), name, str(n_rows), str(n_rows_train)))\n",
        "                df_train = pd.concat([df_train, df.loc[0:n_rows_train,:]], ignore_index = True)\n",
        "                df_test = pd.concat([df_test, df.loc[n_rows_train+1:n_rows_train+n_rows_test,:]], ignore_index = True)\n",
        "                df_val = pd.concat([df_val, df.loc[n_rows_train+n_rows_test+1:n_rows_train+n_rows_test+n_rows_val,:]], ignore_index = True)\n",
        "\n",
        "# removing duplicates\n",
        "df_train.drop_duplicates(inplace = True)\n",
        "df_test.drop_duplicates(inplace = True)\n",
        "df_val.drop_duplicates(inplace = True)\n",
        "\n",
        "print(df_train.groupby(['Class']).count().iloc[:, :1])\n",
        "df_train.to_csv('/content/drive/MyDrive/Freelancer/GraiNit/dvoptic/' + 'DataSetTraining11.csv', index = False)\n",
        "print(df_test.groupby(['Class']).count().iloc[:, :1])\n",
        "df_test.to_csv('/content/drive/MyDrive/Freelancer/GraiNit/dvoptic/' + 'DataSetTest11.csv', index = False)\n",
        "print(df_val.groupby(['Class']).count().iloc[:, :1])\n",
        "df_val.to_csv('/content/drive/MyDrive/Freelancer/GraiNit/dvoptic/' + 'DataSetValidation11.csv', index = False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whSa4hTOKx7h",
        "outputId": "d61090f3-1d60-427b-b47e-812d15d0c8e4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ceramica (04072022_Ceramica_2Merge.csv): 46481, 6391\n",
            "Ceramica (04072022_Ceramica_Sassi0Merge.csv): 40295, 5541\n",
            "Ceramica (04072022_Ceramica_Scure0Merge.csv): 45427, 6246\n",
            "Ceramica (04072022_Ceramica_Latterizio1Merge.csv): 20640, 2838\n",
            "Ceramica (04072022_Ceramica_Colore1Merge.csv): 65016, 8940\n",
            "Ceramica (04072022_Ceramica_Bianca2Merge.csv): 62592, 8606\n",
            "Vetro (04072022_Vetro_5Merge.csv): 54889, 15094\n",
            "Vetro (04072022_Vetro_1Merge.csv): 61725, 16974\n",
            "Plastica (04072022_Plastica_Buona2Merge.csv): 6022, 3312\n",
            "Plastica (04072022_Plastica_Buona1Merge.csv): 30207, 16614\n",
            "Opalino (04072022_Opalino_1Merge.csv): 10311, 5671\n",
            "Opalino (04072022_Opalino_0Merge.csv): 34499, 18974\n",
            "BackGround (04072022_BackGround_All.csv): 520266, 37199\n",
            "Carta (04072022_Carta_Organico.csv): 42612, 11718\n",
            "VetroCeramica (04072022_VetroCeramica_All.csv): 125934, 35324\n",
            "VetroCarta (04072022_VetroCarta_All.csv): 261280, 35926\n",
            "Carta (04072022_Carta_Cartone.csv): 71459, 19651\n",
            "Ceramica (04072022_Ceramica_2Merge (1).csv): 46481, 6391\n",
            "         400\n",
            "Class       \n",
            "0      31371\n",
            "1      35555\n",
            "2      38568\n",
            "3      24647\n",
            "4      19928\n",
            "5      32070\n",
            "6      35245\n",
            "7      37200\n",
            "         400\n",
            "Class       \n",
            "0      11370\n",
            "1      13020\n",
            "2      14023\n",
            "3       8962\n",
            "4       7245\n",
            "5      11661\n",
            "6      12546\n",
            "7      13527\n",
            "         400\n",
            "Class       \n",
            "0      14252\n",
            "1      15934\n",
            "2      17528\n",
            "3      11201\n",
            "4       9056\n",
            "5      14577\n",
            "6      16057\n",
            "7      16909\n"
          ]
        }
      ]
    }
  ]
}