{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNr2EJSA+YNlJoH+80zcTUd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giustinod/nir-data/blob/main/Preparazione_dataset_dvoptic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwZpkhQ3sgY4",
        "outputId": "9e7f14c8-d84b-447f-e9e8-93305e2c1f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.24.77)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.77 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.27.77)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.77->boto3) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.77->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.77->boto3) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spectral in /usr/local/lib/python3.7/dist-packages (0.23)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spectral) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyod) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pyod) (3.2.2)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.7/dist-packages (from pyod) (0.56.2)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.7.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyod) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.0.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod) (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.21.6)\n",
            "Requirement already satisfied: setuptools<60 in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->pyod) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->pyod) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.51->pyod) (4.12.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->pyod) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.51->pyod) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.51->pyod) (4.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (1.4.4)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (1.3.5)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (0.5.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels->pyod) (2022.2.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cleanlab in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from cleanlab) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->cleanlab) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.0->cleanlab) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.0->cleanlab) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->cleanlab) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->cleanlab) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->cleanlab) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikeras[tensorflow] in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikeras[tensorflow]) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=3 in /usr/local/lib/python3.7/dist-packages (from scikeras[tensorflow]) (4.12.0)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikeras[tensorflow]) (21.3)\n",
            "Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from scikeras[tensorflow]) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras[tensorflow]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras[tensorflow]) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=0.21->scikeras[tensorflow]) (3.0.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.5.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.48.1)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.26.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.7.0->scikeras[tensorflow]) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->scikeras[tensorflow]) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.2.0)\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install sklearn\n",
        "!pip3 install boto3\n",
        "!pip3 install spectral\n",
        "!pip3 install pyod\n",
        "!pip3 install cleanlab\n",
        "!pip3 install scikeras[tensorflow]\n",
        "\n",
        "## Import external libraries\n",
        "import os\n",
        "import spectral.io.envi as envi\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import boto3\n",
        "import tensorflow as tf\n",
        "\n",
        "from botocore.exceptions import ClientError\n",
        "from spectral import *\n",
        "from pickle import load\n",
        "from scipy.signal import savgol_filter\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from pyod.models.copod import COPOD\n",
        "\n",
        "def snv(input_data):\n",
        "    # Define a new array and populate it with the corrected data  \n",
        "    # return (input_data - np.mean(input_data, axis=0)) / np.std(input_data, axis=0)\n",
        "    output_data = np.zeros_like(input_data)\n",
        "    for i in range(input_data.shape[0]):\n",
        "      # if np.all(np.std(input_data[i,:]) != 0):\n",
        "      # Apply correction\n",
        "      output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / (np.std(input_data[i,:]))\n",
        "      # else:\n",
        "      # output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:]))\n",
        "    return output_data\n",
        "\n",
        "def plot_matrix(matrixToPlot, title='', classList=[]):\n",
        "    # colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)]\n",
        "    colors = ['b','c','r','g','w','k']\n",
        "    cm = LinearSegmentedColormap.from_list('custom_RGB_cmap', colors, N=len(classList))\n",
        "    norm = plt.Normalize(vmin=0, vmax=len(classList) - 1)\n",
        "    handles = [plt.Rectangle((0, 0), 0, 0, color=cm(norm(i)), label=str(classList[i])) for i in range(len(classList))]\n",
        "    plt.imshow(matrixToPlot, norm=norm, cmap=cm)\n",
        "    plt.legend(handles=handles, title='Class', bbox_to_anchor=(1, 0), loc='lower right', bbox_transform=plt.gcf().transFigure)\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(title + '.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "mpy = COPOD()\n",
        "\n",
        "root = '.'\n",
        "\n",
        "# Aggiunte \n",
        "s3_client = boto3.client('s3', aws_access_key_id = 'AKIAUJ3P4B72GW6QEKNC', \n",
        "                         aws_secret_access_key = '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')\n",
        "\n",
        "def upload_file(file_name, bucket = 'pls-regression', object_name = None):\n",
        "    \"\"\"Upload a file to an S3 bucket\n",
        "\n",
        "    :param file_name: File to upload\n",
        "    :param bucket: Bucket to upload to\n",
        "    :param object_name: S3 object name. If not specified then file_name is used\n",
        "    :return: True if file was uploaded, else False\n",
        "    \"\"\"\n",
        "\n",
        "    # If S3 object_name was not specified, use file_name\n",
        "    if object_name is None:\n",
        "        object_name = os.path.basename(file_name)\n",
        "\n",
        "    # Upload the file\n",
        "    try:\n",
        "        response = s3_client.upload_file(file_name, bucket, 'saved_models/' + object_name)\n",
        "    except ClientError as e:\n",
        "        logging.error(e)\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "import scipy\n",
        "from scipy import newaxis as nA\n",
        "\n",
        "def mlr(x, y, order):\n",
        "    \"\"\"Multiple linear regression fit of the columns of matrix x \n",
        "    (dependent variables) to constituent vector y (independent variables)\n",
        "    \n",
        "    order -     order of a smoothing polynomial, which can be included \n",
        "                in the set of independent variables. If order is\n",
        "                not specified, no background will be included.\n",
        "    b -         fit coeffs\n",
        "    f -         fit result (m x 1 column vector)\n",
        "    r -         residual   (m x 1 column vector)\n",
        "    \"\"\"\n",
        "    if order > 0:\n",
        "        s = scipy.ones((len(y),1))\n",
        "        for j in range(order):\n",
        "            s = scipy.concatenate((s,(scipy.arange(0,1+(1.0/(len(y)-1)),1.0/(len(y)-1))**j)[:x.shape[0],nA]), 1)\n",
        "        X = scipy.concatenate((x, s), 1)\n",
        "    else:\n",
        "        X = x\n",
        "    \n",
        "    #calc fit b=fit coefficients\n",
        "    b = scipy.dot(scipy.dot(scipy.linalg.pinv(scipy.dot(scipy.transpose(X),X)),scipy.transpose(X)),y)\n",
        "    f = scipy.dot(X,b)\n",
        "    r = y - f\n",
        "\n",
        "    return b,f,r\n",
        "\n",
        "def emsc(myarray, order = 1, fit = None):\n",
        "    \"\"\"Extended multiplicative scatter correction (Ref H. Martens)\n",
        "    myarray -   spectral data for background correction\n",
        "    order -     order of polynomial\n",
        "    fit -       if None then use average spectrum, otherwise provide a spectrum\n",
        "                as a column vector to which all others fitted\n",
        "    corr -      EMSC corrected data\n",
        "    mx -        fitting spectrum\n",
        "    \"\"\"\n",
        "    \n",
        "    #choose fitting vector\n",
        "    if fit:\n",
        "        mx = fit\n",
        "    else:\n",
        "        mx = scipy.mean(myarray, axis=0)[:,nA]\n",
        "\n",
        "    #do fitting\n",
        "    corr = scipy.zeros(myarray.shape)\n",
        "    for i in range(len(myarray)):\n",
        "        if np.count_nonzero(myarray[i,:]) > 0:\n",
        "            b,f,r = mlr(mx, myarray[i,:][:,nA], order)\n",
        "            corr[i,:] = scipy.reshape((r/b[0,0]) + mx, (corr.shape[1],))\n",
        "\n",
        "    assert not np.any(np.isnan(corr))\n",
        "    return corr\n",
        "\n",
        "import multiprocessing\n",
        "import time\n",
        "from datetime import datetime\n",
        "import concurrent.futures\n",
        "from multiprocessing import Process\n",
        "\n",
        "def data_augmentation(scan):\n",
        "  ## Standardize on columns\n",
        "  if np.count_nonzero(scan) > 0:\n",
        "      svn_scan = snv(scan)\n",
        "      msc_scan = emsc(scan)\n",
        "      scan1 = np.concatenate((scan, svn_scan, msc_scan,\\\n",
        "                  savgol_filter(scan, w, polyorder = p, deriv=1),\\\n",
        "                  savgol_filter(svn_scan, w, polyorder = p, deriv=1),\\\n",
        "                  savgol_filter(msc_scan, w, polyorder = p, deriv=1)), axis = 1)\n",
        "  else:\n",
        "      scan1 = np.zeros((scan.shape[0], scan.shape[1] * 6), dtype=np.float32)\n",
        "\n",
        "  print('{} - Data augmentation chunk: {} -> {}'.format(datetime.now(), scan.shape, scan1.shape))\n",
        "  return scan1\n",
        "\n",
        "# Check speculari\n",
        "def outliers_speculari(input_data):\n",
        "\n",
        "  ''' Restituisce gli indici degli spettri che hanno caratteristiche di speculari'''\n",
        "  # per lo spettro IR [1050,1650]nm assumiamo:\n",
        "  IR_delta_max = 0.5\n",
        "  IR_lambda_max = 1.2\n",
        "  # per lo spettro VNIR [[400, 600], [800, 900]]nm assumiamo:\n",
        "  VNIR_lambda_max = 1.2\n",
        "\n",
        "  offset = int((1010 - 400) / 10)\n",
        "  offset2 = int((600 - 400) / 10)\n",
        "  offset3 = int((800 - 400) / 10)\n",
        "  offset4 = int((900 - 400) / 10)\n",
        "  speculari_VNIR = np.where((np.max(input_data[:, :offset2], axis = 1) > VNIR_lambda_max) | (np.max(input_data[:, offset3:offset4], axis = 1) > VNIR_lambda_max)) \n",
        "  speculari_IR = np.where((np.max(input_data[:, offset + 1:], axis = 1) > IR_lambda_max) | ((np.max(input_data[:, offset + 1:], axis = 1) - np.min(input_data[:, offset + 1:], axis = 1)) > IR_delta_max))\n",
        "\n",
        "  # print('Speculari IR: ', speculari_IR)\n",
        "  # print('Speculari VNIR: ', speculari_VNIR)\n",
        "  speculari = np.unique(np.concatenate((speculari_IR[0], speculari_VNIR[0]), axis=0))\n",
        "  # print('Speculari: ', speculari)\n",
        "  return speculari\n",
        "\n",
        "selected_classes = (0, 1, 2, 3, 4, 5, 6, 7)\n",
        "n_classes = len(selected_classes)\n",
        "\n",
        "## Settings for the smooth derivatives using a Savitsky-Golay filter\n",
        "w = 7 ## Sav.Gol window size\n",
        "p = 2 ## Sav.Gol polynomial degree\n",
        "\n",
        "n_features = 182\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth, data_table\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "root = '/content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/'\n",
        "\n",
        "# cfr. https://stackoverflow.com/questions/9132114/indexing-numpy-array-neighbours-efficiently\n",
        "def neighbors(x):\n",
        "    return np.array([x-3, x-2, x-1, x, x+1, x+2, x+3])\n",
        "\n",
        "for path, subdirs, files in os.walk(root):\n",
        "    # print('Path: ', path)\n",
        "    for name in files:\n",
        "        if name.endswith('hdr'):\n",
        "            print('{} - Opening {}'.format(datetime.now(), os.path.join(path, name)))\n",
        "            MyImg = envi.open(os.path.join(path, name))\n",
        "            np_img = np.array(MyImg.load())\n",
        "            # print('{} - Image shape: {}'.format(datetime.now(), np_img.shape))\n",
        "            # print('{} - Image rows*cols: {}*{}'.format(datetime.now(), MyImg.nrows, MyImg.ncols))\n",
        "            X = np.resize(np_img, (np_img.shape[0] * np_img.shape[1], np_img.shape[2]))\n",
        "            # print('{} - Conv. to Numpy array {}'.format(datetime.now(), X.shape))\n",
        "            # spec_outliers = outliers_speculari(X)\n",
        "            # print('{} - Outliers Speculari # {}'.format(datetime.now(), np.unique(spec_outliers).shape))\n",
        "            # fitted = mpy.fit(X)\n",
        "            # c_outliers = mpy.predict(X)\n",
        "            # copod_outliers = np.where(c_outliers >= 1)\n",
        "            # print('{} - Outliers COPOD # {}'.format(datetime.now(), copod_outliers[0].shape))\n",
        "            # mask_outliers = spec_outliers # np.unique(np.concatenate((spec_outliers, copod_outliers[0])))\n",
        "            mask_all_zeroes = np.where(~X.any(axis=1))[0]\n",
        "            nb_all_zeroes = np.unique(np.concatenate([neighbors(i) for i in mask_all_zeroes]))\n",
        "            # print('{} - Rows having all zeroes # {}'.format(datetime.now(), mask_all_zeroes))\n",
        "            # print('{} - Rows having all zeroes in the neighborhood # {} - {}'.format(datetime.now(), nb_all_zeroes, nb_all_zeroes.shape))\n",
        "            nb_all_zeroes = np.delete(nb_all_zeroes, [0, 1, 2, nb_all_zeroes.shape[0]-3, nb_all_zeroes.shape[0]-2, nb_all_zeroes.shape[0]-1], axis = 0)\n",
        "            X = np.delete(X, nb_all_zeroes, axis = 0)\n",
        "            # print('{} - Rows having all zeroes in the neighborhood # {} - {}'.format(datetime.now(), nb_all_zeroes, nb_all_zeroes.shape))\n",
        "            print('{} - Result size # {}'.format(datetime.now(), X.shape))\n",
        "            cols = np.concatenate([np.arange(400, 1010, 10), np.arange(1050, 1655, 5)])\n",
        "            df = pd.DataFrame(X, columns = cols)\n",
        "            date_ = name.split('_')[0]\n",
        "            class_ = name.split('_')[1]\n",
        "            class_col = np.full(X.shape[0], class_)\n",
        "            csv = df.insert(0, \"Class\", class_col)\n",
        "            filename = name.replace('hdr', 'csv')\n",
        "            print('{} - csv # {}'.format(datetime.now(), filename))\n",
        "            df.to_csv('/content/drive/MyDrive/Freelancer/GraiNit/dvoptic/training/' + filename, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdgtY5To-w6h",
        "outputId": "78cff76a-177c-4084-e14c-f6d0f6f520b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "2022-09-21 13:25:38.738444 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/23062022_Ceramica_2Merge.hdr\n",
            "2022-09-21 13:25:39.685606 - Result size # (46481, 182)\n",
            "2022-09-21 13:25:39.690790 - csv # 23062022_Ceramica_2Merge.csv\n",
            "2022-09-21 13:25:46.427900 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Ceramica_Sassi0Merge.hdr\n",
            "2022-09-21 13:25:47.388576 - Result size # (40295, 182)\n",
            "2022-09-21 13:25:47.393116 - csv # 04072022_Ceramica_Sassi0Merge.csv\n",
            "2022-09-21 13:25:53.693860 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Ceramica_Scure0Merge.hdr\n",
            "2022-09-21 13:25:54.714618 - Result size # (45427, 182)\n",
            "2022-09-21 13:25:54.719631 - csv # 04072022_Ceramica_Scure0Merge.csv\n",
            "2022-09-21 13:26:01.670284 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Ceramica_Latterizio1Merge.hdr\n",
            "2022-09-21 13:26:02.705008 - Result size # (20640, 182)\n",
            "2022-09-21 13:26:02.708446 - csv # 04072022_Ceramica_Latterizio1Merge.csv\n",
            "2022-09-21 13:26:05.768877 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Ceramica_Colore1Merge.hdr\n",
            "2022-09-21 13:26:06.865156 - Result size # (65016, 182)\n",
            "2022-09-21 13:26:06.881813 - csv # 04072022_Ceramica_Colore1Merge.csv\n",
            "2022-09-21 13:26:18.349566 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Ceramica_Bianca2Merge.hdr\n",
            "2022-09-21 13:26:19.263925 - Result size # (62592, 182)\n",
            "2022-09-21 13:26:19.270317 - csv # 04072022_Ceramica_Bianca2Merge.csv\n",
            "2022-09-21 13:26:29.026891 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Vetro_5Merge.hdr\n",
            "2022-09-21 13:26:29.955339 - Result size # (54889, 182)\n",
            "2022-09-21 13:26:29.960071 - csv # 04072022_Vetro_5Merge.csv\n",
            "2022-09-21 13:26:38.868360 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Vetro_1Merge.hdr\n",
            "2022-09-21 13:26:41.383745 - Result size # (61725, 182)\n",
            "2022-09-21 13:26:41.389132 - csv # 04072022_Vetro_1Merge.csv\n",
            "2022-09-21 13:26:51.245293 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Plastica_Buona2Merge.hdr\n",
            "2022-09-21 13:26:54.614694 - Result size # (6022, 182)\n",
            "2022-09-21 13:26:54.617491 - csv # 04072022_Plastica_Buona2Merge.csv\n",
            "2022-09-21 13:26:55.521502 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Plastica_Buona1Merge.hdr\n",
            "2022-09-21 13:26:58.816067 - Result size # (30207, 182)\n",
            "2022-09-21 13:26:58.821892 - csv # 04072022_Plastica_Buona1Merge.csv\n",
            "2022-09-21 13:27:03.741810 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Opalino_1Merge.hdr\n",
            "2022-09-21 13:27:06.936578 - Result size # (10311, 182)\n",
            "2022-09-21 13:27:06.939118 - csv # 04072022_Opalino_1Merge.csv\n",
            "2022-09-21 13:27:08.499128 - Opening /content/drive/MyDrive/Freelancer/GraiNit/dvoptic/merge/04072022_Opalino_0Merge.hdr\n",
            "2022-09-21 13:27:11.609351 - Result size # (34499, 182)\n",
            "2022-09-21 13:27:11.613451 - csv # 04072022_Opalino_0Merge.csv\n"
          ]
        }
      ]
    }
  ]
}